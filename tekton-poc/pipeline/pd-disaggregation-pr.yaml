apiVersion: tekton.dev/v1
kind: PipelineRun
metadata:
  name: pd
spec:
  taskRunTemplate:
    serviceAccountName: helm-installer
  workspaces:
    - name: data
      persistentVolumeClaim:
        claimName: workspace-pvc
  params:
    - name: targetNamespacePrefix
      # This can be anything.
      value: $(context.pipelineRun.namespace)
    - name: model-id
      value: "meta-llama/Llama-3.1-8B-Instruct"

    # Harness / Workload
    - name: harnessName
      value: vllm-benchmark
    - name: harnessProfile
      value: random_concurrent.yaml

    # Output Location
    - name: s3-keys
      value: ibm-cos-secret
    - name: s3-bucket
      value: "cloud-object-storage-cos-standard-ere"
    - name: s3-endpoint
      value: "https://s3.us-east.cloud-object-storage.appdomain.cloud"

    # Control
    - name: debug
      value: true

  pipelineSpec:
    workspaces:
      - name: data
    tasks:
      - name: run-experiment
        taskRef:
          name: experiment
        workspaces:
          - name: data
            workspace: data
        params:
          - name: targetNamespacePrefix
            value: $(params.targetNamespacePrefix)
          - name: model-id
            value: $(params.model-id)
          - name: experimentBaseUrl
            value: https://raw.githubusercontent.com/kalantar/llm-d-benchmark/refs/heads/tekton-poc/tekton-poc/examples/pd-disaggregation/

          - name: s3-keys
            value: $(params.s3-keys)
          - name: s3-bucket
            value: $(params.s3-bucket)
          - name: s3-endpoint
            value: $(params.s3-endpoint)

          - name: harnessName
            value: $(params.harnessName)
          - name: harnessProfile
            value: $(params.harnessProfile)

          - name: factorMapping
            value: |
              {
                "modelservice": {
                  "prefillReplicas": "prefill.replicas",
                  "prefillTensorParallelism":  "prefill.parallelism.tensor",
                  "decodeReplicas": "decode.replicas",
                  "decodeTensorParallelism":  "decode.parallelism.tensor"
                },
                "gaie": {
                  "gaiePluginConfig": "inferenceExtension.pluginsConfigFile"
                },
                "workload": {
                  "max-concurrency": "max-concurrency",
                  "num_prompts": "num-prompts",
                  "question_len": "data.shared_prefix.question_len",
                  "output_len": "data.shared_prefix.output_len"
                }
              }

          - name: debug
            value: "$(params.debug)"
          - name: pipelineUID
            value: "$(context.pipelineRun.uid)"

        matrix:
          include:
            - name: combo-0
              params:
                - name: treatment
                  value: |
                    {
                      "prefillReplicas": 1,
                      "prefillTensorParallelism": 1,
                      "decodeReplicas": 1,
                      "decodeTensorParallelism": 1,
                      "max-concurrency": 1,
                      "num-prompts": 10
                    }
            # - name: combo-1
            #   params:
            #     - name: treatment
            #       value: |
            #         {
            #           "prefillReplicas": 1,
            #           "prefillTensorParallelism": 2,
            #           "decodeReplicas": 1,
            #           "decodeTensorParallelism": 1,
            #           "max-concurrency": 1,
            #           "num-prompts": 10
            #         }

          # params:
          #   - name: max-concurrency
          #     value:
          #       - "1"
          #       # - "8"
          #       # - "32"
          #       # - "64"
          #       # - "128"
          #       # - "256"
          #   - name: num-prompts
          #     value: 
          #       - "10"
          #       # - "80"
          #       # - "320"
          #       # - "640"
          #       # - "1280"
          #       # - "2560"

# LLMDBENCH_VLLM_COMMON_REPLICAS: "2,4"
#   decode.replicas
# LLMDBENCH_VLLM_COMMON_TENSOR_PARALLELISM: "8"
#   decode.parallelism.tensor

# LLMDBENCH_VLLM_MODELSERVICE_PREFILL_REPLICAS: "2,4,6,8"
#   prefill.replicas
# LLMDBENCH_VLLM_MODELSERVICE_PREFILL_TENSOR_PARALLELISM: "1,2"
#   prefill.parallelism.tensor
# LLMDBENCH_VLLM_MODELSERVICE_DECODE_REPLICAS: "1,2,4"
#   decode.replicas
# LLMDBENCH_VLLM_MODELSERVICE_DECODE_TENSOR_PARALLELISM: "2,4,8"
#   decodeTensorParallelism
#   decode.parallelism.tensor