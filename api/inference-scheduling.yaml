metadata:
  # A short, unique suite identifier (used for naming runs and outputs).
  name: inference-scheduling
  # One or two sentences describing what this suite explores.
  description: >
    Defines an experiment to test the llm-d inference-scheduling well lit path.
    This experiment tests the behavior of different inference-scheduling algorithms.

# -----------------------------------------------------------------------------
# configuration
# -----------------------------------------------------------------------------
# Minimal, global settings independent of any particular experiment case.
# - namespace: where resources for this suite are created.
# - output: location where experiment output should be written. This is a 
#           one of git, s3, or googledrive and a dir.
# - output.dir: the location on the target medium where a directory of the results should be written.
# - source: the location of a directory on the results PVC where sweep steps will write results
configuration:
  namespace: kalantar-test
  output:
    target: # support s3, git (first), cos, googledrive
      git:
        secretRef: gitsecret  # should contain fields username and password
        repository: github.com/kalantar/llm-d-data
        branch: main
      dir: kalantar/inference-scheduling
    source:
      pvc:
        # flag indicating whether or not the PVC should be created as part of the experiment execution.
        create: false
        name: workload-pvc
        # size of the volume that should be created. Ignored if create: false
        size: 20 Gi
        # storageClass is the StorageClass of the PVC to create. Ignored if created: false
        # The selected StorageClass MUST support the RWX access mode.
        storageClass: default
      # location relative the mount location where a directory containing the results of all sweeps should be written.
      dir: kalantar/inference-scheduling
  hfsecret: llm-d-hf-token
  model: Qwen/Qwen3-0.6B

# -----------------------------------------------------------------------------
# components
# -----------------------------------------------------------------------------
# Lists the configurable parts of the system under test AND the workload generator.
# For each component you may define one or more named options. These options
# CAN be axis of the sweepSpace.
# Only components that need to be deployed or may be modified during an experiment
# SHOULD to be specified.
# For each option, either a configUrl or a config MUST be specified. A configUrl
# references a manifest that should be deployed to create the component.
# A config is an inlined manifest; ie yaml string.
components:

  # ---------------------------------------------------------------------------
  # model-cache component
  # ---------------------------------------------------------------------------
  # A PVC where models may be downloaded from huggingface
  - component: model-cache
    options:
      - name: model-cache
        config: |
          apiVersion: v1
          kind: PersistentVolumeClaim
          metadata:
            name: model-pvc
          spec:
            accessModes:
            - ReadWriteMany
            resources:
              requests:
                storage: 300Gi
            storageClassName: default
            volumeMode: Filesystem

  # ---------------------------------------------------------------------------
  # model-download component
  # ---------------------------------------------------------------------------
  # Mechanism to place the model where it should be
  - component: model-download
    options:
      - name: model
        configUrl: https://raw.githubusercontent.com/kalantar/llm-d-benchmark/refs/heads/proposed-api/api/download-job.yaml
        vars:
          - name: hfSecret
            object: job/download-model
            path: .spec.template.spec.containers[?(@.name=="downloader")].env[?(@.name=="HF_TOKEN")].valueFrom.secretKeyRef.name
            default: { $.configuration.hfsecret }
          - name: model
            object: job/download-model
            path: .spec.template.spec.containers[?(@.name=="downloader")].env[?(@.name=="HF_MODEL_ID")].value
            default: { $.configuration.model }
          - name: modelPath
            object: job/download-model
            path: .spec.template.spec.containers[?(@.name=="downloader")].env[?(@.name=="MODEL_PATH")].value
            default: /models/{ $.configuration.model }
          - name: pvcName
            object: job/download-model
            path: .spec.template.spec.volumes[?(@.name=="model-cache")].persistentVolumeClaim
            default: model-pvc

  # ---------------------------------------------------------------------------
  # gateway component
  # ---------------------------------------------------------------------------
  # Zero or one gateway profile may be selected by the sweep.
  # If this section is omitted entirely, the runner should assume a gateway
  # is already deployed and should not be modified by this suite.
  #
  # - component:
  #   options:
  #     - name: istio
  #       config: https://github.com/example-org/istio-gateway.yaml

  # ---------------------------------------------------------------------------
  # gaie component
  # ---------------------------------------------------------------------------
  # One of these profiles may be selected by the sweep to configure the
  # Kubernetes Gateway API Inference Extension (gaie) behavior (e.g., default vs.
  # scheduler-backed with different picker strategies).
  #
  # If this section is omitted or no profile is selected, the runner should assume
  # the extension configuration is already present and will remain unchanged.
  # Mostly created with helm
  # Created cm portion using: kubectl create cm mygaie-epp --dry-run=client --from-file=setup/presets/gaie -o yaml > api/mygaie-cm.yaml
  - component: gaie
    options:
      - name: gaie
        configUrl: https://raw.githubusercontent.com/kalantar/llm-d-benchmark/refs/heads/proposed-api/api/gaie.yaml
        vars:
          - name: profile
            object: deployment/mygaie-epp
            path: .spec.template.spec.containers.args[=--config-file]
            default: default.yaml

  # ---------------------------------------------------------------------------
  # vllm component
  # ---------------------------------------------------------------------------
  # Defines the model serving layer. Zero or more options can be specified.
  # Created using modelservice.
  - component: vllm
    options:
      - name: vllm
        configUrl: https://raw.githubusercontent.com/kalantar/llm-d-benchmark/refs/heads/proposed-api/api/vllm.yaml        # readiness: to check that this is complete

  # ---------------------------------------------------------------------------
  # workload-profile component
  # ---------------------------------------------------------------------------
  # Creates a ConfigMap with configuration of the workload profiles.
  # This ConfigMap is required to configure the workload component.
  # Created using: kubectl create cm ${workload_type}-profile --dry-run=client --from-file=workload/profiles/${workload_type} -o yaml > api/${workload_type}-profiles.yaml
  - component: workload-profile
    options:
      - name: shared_prefix_synthetic
        configUrl: https://raw.githubusercontent.com/kalantar/llm-d-benchmark/refs/heads/proposed-api/api/inference-perf.yaml
        vars:
          - name: question_len
            object: configmap/inference-perf-profiles
            path: .data.shared_prefix.question_len
          - name: output_len
            object: configmap/inference-perf-profiles
            path: .data.shared_prefix.output_len

  # ---------------------------------------------------------------------------
  # harness component
  # ---------------------------------------------------------------------------
  # Exactly one harness must be defined here. The `harness` value identifies the
  # load generator and should be one of: fmperf | inference-perf | guildllm | dllm-bench
  # (Confirm the spelling of 'guildllm' vs. your preferred tool name.)
  #
  # `config` points to a reference containing the workload job/runner definition.
  #
  # Variables here are typical load-intensity settings; the sweep can override them
  # via matching axis names in `sweepSpace.axes`.
  # Created by hand.
  - component: harness
    options:
      - name: inference-perf
        configUrl: https://raw.githubusercontent.com/kalantar/llm-d-benchmark/refs/heads/proposed-api/api/harnesses.yaml
        vars:
          - name: LLMDBENCH_HARNESS_STACK_ENDPOINT_URL
            path: .spec.template.spec.containers[?(@.name=="harness")].env[?(@.name=="LLMDBENCH_HARNESS_STACK_ENDPOINT_URL")].value
            default: TBD
          - name: LLMDBENCH_RUN_EXPERIMENT_HARNESS_WORKLOAD_NAME
            path: .spec.template.spec.containers[?(@.name=="harness")].env[?(@.name=="LLMDBENCH_RUN_EXPERIMENT_HARNESS_WORKLOAD_NAME")].value
            default: shared_prefix_synthetic.yaml.in
          - name: LLMDBENCH_HARNESS_NAMESPACE
            path: .spec.template.spec.containers[?(@.name=="harness")].env[?(@.name=="LLMDBENCH_HARNESS_NAMESPACE")].value
            default: { $.configuration.namespace }
          - name: LLMDBENCH_RUN_EXPERIMENT_ID
            path: .spec.template.spec.containers[?(@.name=="harness")].env[?(@.name=="LLMDBENCH_RUN_EXPERIMENT_ID")].value
            default: TBD
          - name: LLMDBENCH_RUN_EXPERIMENT_RESULTS_DIR
            path: .spec.template.spec.containers[?(@.name=="harness")].env[?(@.name=="LLMDBENCH_RUN_EXPERIMENT_RESULTS_DIR")].value
            default: TBD
          - name: LLMDBENCH_CONTROL_WORK_DIR
            path: .spec.template.spec.containers[?(@.name=="harness")].env[?(@.name=="LLMDBENCH_CONTROL_WORK_DIR")].value
            default: TBD
          - name: LLMDBENCH_HARNESS_STACK_TYPE
            path: .spec.template.spec.containers[?(@.name=="harness")].env[?(@.name=="LLMDBENCH_HARNESS_STACK_TYPE")].value
            default: TBD
          - name: LLMDBENCH_HARNESS_STACK_NAME
            path: .spec.template.spec.containers[?(@.name=="harness")].env[?(@.name=="LLMDBENCH_HARNESS_STACK_NAME")].value
            default: TBD
          - name: HUGGING_FACE_HUB_TOKEN
            path: .spec.template.spec.containers[?(@.name=="harness")].env[?(@.name=="HUGGING_FACE_HUB_TOKEN")].valueFrom.secretKeyRef.name
            default: { $.configuration.hfsecret }
          - name: HF_TOKEN_SECRET
            path: .spec.template.spec.containers[?(@.name=="harness")].env[?(@.name=="HF_TOKEN_SECRET")].value
            default: { $.configuration.hfsecret }

          - name: resultsPvc
            path: .spec.template.spec.volumes[?(@.name=="results")].persistentVolumeClaim.claimName
            default: ${ .configuration.source.pvc.name }

# -----------------------------------------------------------------------------
# sweepSpace
# -----------------------------------------------------------------------------
# Describes combinations and WHICH of them to try.
#
# - `axes`: declares the dimensions and value sets to combine.
#   Each axis name MUST match a variable name in one of the above `vars`
#   lists OR a profile/option selector under `components` (like `gaie`
#   or `vllm`). When an axis matches a variable name, it overrides that variableâ€™s
#   default for the corresponding runs.
#
# - By default (if `include` is empty or not present), a runner MAY treat `axes`
#   as a request for a full Cartesian product across all value lists.
#
# - `constraint`: identifies relationships that must or must not hold between variables being
#   swept. Invalid combinations are ignored.
sweepSpace:
  axes:
    - variables:
      - gaie/gaie/profile
      levels:
        - name: default
          values: [default]
        - name: cache_estimate
          values: [prefix-cache-estimate-config]
        - name: cache_tracking
          values: [prefix-cache-tracking-config]

    - variables: 
        - workload-profile/shared_prefix_synthetic/question_len
        - workload-profile/shared_prefix_synthetic/output_len
      levels:
        - values: [100,100]
        - values: [100,300]
        - values: [100,1000]
        - values: [300,100]
        - values: [300,300]
        - values: [300,1000]
        - values: [1000,100]
        - values: [1000,300]
        - values: [1000,1000]

  # constraint:
